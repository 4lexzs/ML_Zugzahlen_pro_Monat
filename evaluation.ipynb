{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2470d342-5473-4bf0-84be-82bdd116b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1 Feature Importance Analysis\n",
      "================================\n",
      "\n",
      "Top 10 wichtigste Features:\n",
      "                                                Feature  Importance\n",
      "1396           Abschnitt_Zürich HB – Zürich Langstrasse    0.064449\n",
      "26       Strecke_Bezeichnung_Genève Aéroport - Lausanne    0.047000\n",
      "58    Strecke_Bezeichnung_Olten Ost - Heitersberg - ...    0.046724\n",
      "35    Strecke_Bezeichnung_Killwangen - Zürich Altste...    0.043938\n",
      "110   Strecke_Bezeichnung_Zürich Oerlikon-Nord / Zür...    0.036875\n",
      "8                              Strecke_Bezeichnung_Bern    0.027580\n",
      "1401   Abschnitt_Zürich Hardbrücke – Zürich Langstrasse    0.025871\n",
      "1                             Strecke_Bezeichnung_Aarau    0.025632\n",
      "53       Strecke_Bezeichnung_Muttenz - HBT - Olten Nord    0.024355\n",
      "1410  Abschnitt_Zürich Oerlikon – Zürich Birchsteg (...    0.022348\n",
      "\n",
      "4.2 Geeignete Messmetrik\n",
      "========================\n",
      "\n",
      "Für dieses Regressionsmodell sind folgende Metriken geeignet:\n",
      "R² Score: 0.9951\n",
      "Mean Absolute Error (MAE): 4.53\n",
      "Root Mean Square Error (RMSE): 12.19\n",
      "Mean Absolute Percentage Error (MAPE): inf%\n",
      "\n",
      "Die beste Metrik für dieses Modell ist der R² Score, da er zeigt,\n",
      "wie gut das Modell die Varianz in den Daten erklärt.\n",
      "\n",
      "4.3 Confusion Matrix und Klassifikation\n",
      "=======================================\n",
      "\n",
      "Confusion Matrix:\n",
      "         Niedrig  Mittel  Hoch\n",
      "Niedrig     1247      18     0\n",
      "Mittel        16    1368     9\n",
      "Hoch           1      22   468\n",
      "\n",
      "Sensitivität (Recall) und Präzision für jede Kategorie:\n",
      "\n",
      "Niedrig:\n",
      "  Sensitivität (Recall): 0.9532\n",
      "  Präzision: 0.9811\n",
      "\n",
      "Mittel:\n",
      "  Sensitivität (Recall): 0.9821\n",
      "  Präzision: 0.9716\n",
      "\n",
      "Hoch:\n",
      "  Sensitivität (Recall): 0.9858\n",
      "  Präzision: 0.9866\n",
      "\n",
      "Spezifizität für jede Kategorie:\n",
      "Niedrig: 0.9910\n",
      "Mittel: 0.9772\n",
      "Hoch: 0.9966\n",
      "\n",
      "4.4 Zusammenfassung der Modellleistung\n",
      "======================================\n",
      "\n",
      "Das entwickelte Random Forest Regressionsmodell zeigt eine ausgezeichnete Leistung:\n",
      "\n",
      "Hauptmetriken:\n",
      "- R² Score: 0.9951 (erklärt 99.5% der Varianz)\n",
      "- Mean Absolute Error: 4.5 Züge pro Tag\n",
      "- RMSE: 12.2 Züge pro Tag\n",
      "- MAPE: inf%\n",
      "\n",
      "Gründe für die gute Leistung:\n",
      "1. Die Zugzahlen zeigen starke zeitliche Muster (Monat, Jahr), die das Modell gut erfassen kann\n",
      "2. Streckenspezifische Charakteristiken sind wichtige Vorhersagefaktoren  \n",
      "3. Random Forest kann gut mit kategorialen Variablen umgehen\n",
      "4. Der Datensatz ist gross genug für robuste Vorhersagen\n",
      "\n",
      "Verbesserungspotenzial:\n",
      "1. Integration von Wetterinformationen\n",
      "2. Berücksichtigung von Feiertagen und Schulferien\n",
      "3. Analyse von Wochentag-Effekten\n",
      "4. Längsschnittanalyse zur besseren Trenderfassung\n",
      "\n",
      "\n",
      "Analyse abgeschlossen!\n",
      "\n",
      "Erstellt wurden folgende Dateien:\n",
      "- feature_importance.png\n",
      "- confusion_matrix.png\n",
      "- actual_vs_predicted.png\n",
      "\n",
      "Bereit für Teil 4 der Leistungsbeurteilung!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Teil 4\n",
    "# Leistungsbeurteilung 259 - Maschinelles Lernen\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Daten laden (passt den Dateinamen an deinen an!)\n",
    "df = pd.read_csv('zugzahlen_pro_monat.csv', delimiter=';', encoding='utf-8')\n",
    "\n",
    "# Daten vorbereiten\n",
    "df['bezugsmonat_dt'] = pd.to_datetime(df['bezugsmonat'])\n",
    "df['Jahr'] = df['bezugsmonat_dt'].dt.year  \n",
    "df['Monat'] = df['bezugsmonat_dt'].dt.month\n",
    "\n",
    "# One-Hot-Encoding\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_strecke = ohe.fit_transform(df[['Strecke_Bezeichnung', 'Abschnitt']])\n",
    "encoded_columns = ohe.get_feature_names_out(['Strecke_Bezeichnung', 'Abschnitt'])\n",
    "df_encoded = pd.DataFrame(encoded_strecke, columns=encoded_columns)\n",
    "\n",
    "# Features zusammenführen\n",
    "X = pd.concat([df_encoded, df[['Jahr', 'Monat']]], axis=1)\n",
    "y = pd.to_numeric(df['DTV_Bezugsmonat'], errors='coerce')\n",
    "\n",
    "# Fehlende Werte entfernen\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Modell\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ========================================\n",
    "# 4.1 Feature Importance\n",
    "# ========================================\n",
    "print(\"4.1 Feature Importance Analysis\")\n",
    "print(\"================================\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 wichtigste Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Feature Importance Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_10_features = feature_importance.head(10)\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features)\n",
    "plt.title('Top 10 wichtigste Features für das Modell')\n",
    "plt.xlabel('Relative Wichtigkeit')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ========================================\n",
    "# 4.2 Metriken\n",
    "# ========================================\n",
    "print(\"\\n4.2 Geeignete Messmetrik\")\n",
    "print(\"========================\")\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "print(f\"\\nFür dieses Regressionsmodell sind folgende Metriken geeignet:\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"\\nDie beste Metrik für dieses Modell ist der R² Score, da er zeigt,\")\n",
    "print(f\"wie gut das Modell die Varianz in den Daten erklärt.\")\n",
    "\n",
    "# ========================================\n",
    "# 4.3 Confusion Matrix\n",
    "# ========================================\n",
    "print(\"\\n4.3 Confusion Matrix und Klassifikation\")\n",
    "print(\"=======================================\")\n",
    "\n",
    "# Kategorisierung\n",
    "def categorize_traffic(value):\n",
    "    if value < 100:\n",
    "        return 'Niedrig'\n",
    "    elif value < 300:\n",
    "        return 'Mittel'\n",
    "    else:\n",
    "        return 'Hoch'\n",
    "\n",
    "y_test_cat = y_test.apply(categorize_traffic)\n",
    "y_pred_cat = pd.Series(y_pred).apply(categorize_traffic)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_cat, y_pred_cat, labels=['Niedrig', 'Mittel', 'Hoch'])\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, \n",
    "                              index=['Niedrig', 'Mittel', 'Hoch'], \n",
    "                              columns=['Niedrig', 'Mittel', 'Hoch'])\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Zugkategorien')\n",
    "plt.xlabel('Vorhergesagte Kategorie')\n",
    "plt.ylabel('Tatsächliche Kategorie')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Berechnung von Metriken\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test_cat, y_pred_cat, average=None)\n",
    "categories = ['Niedrig', 'Mittel', 'Hoch']\n",
    "\n",
    "print(\"\\nSensitivität (Recall) und Präzision für jede Kategorie:\")\n",
    "for i, cat in enumerate(categories):\n",
    "    print(f\"\\n{cat}:\")\n",
    "    print(f\"  Sensitivität (Recall): {recall[i]:.4f}\")\n",
    "    print(f\"  Präzision: {precision[i]:.4f}\")\n",
    "\n",
    "# Spezifizität berechnen\n",
    "print(\"\\nSpezifizität für jede Kategorie:\")\n",
    "for i, cat in enumerate(categories):\n",
    "    tn = np.sum(conf_matrix) - conf_matrix[i,:].sum() - conf_matrix[:,i].sum() + conf_matrix[i,i]\n",
    "    fp = conf_matrix[:,i].sum() - conf_matrix[i,i]\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"{cat}: {specificity:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# 4.4 Zusammenfassung\n",
    "# ========================================\n",
    "print(\"\\n4.4 Zusammenfassung der Modellleistung\")\n",
    "print(\"======================================\")\n",
    "\n",
    "summary = f\"\"\"\n",
    "Das entwickelte Random Forest Regressionsmodell zeigt eine ausgezeichnete Leistung:\n",
    "\n",
    "Hauptmetriken:\n",
    "- R² Score: {r2:.4f} (erklärt {r2*100:.1f}% der Varianz)\n",
    "- Mean Absolute Error: {mae:.1f} Züge pro Tag\n",
    "- RMSE: {rmse:.1f} Züge pro Tag\n",
    "- MAPE: {mape:.1f}%\n",
    "\n",
    "Gründe für die gute Leistung:\n",
    "1. Die Zugzahlen zeigen starke zeitliche Muster (Monat, Jahr), die das Modell gut erfassen kann\n",
    "2. Streckenspezifische Charakteristiken sind wichtige Vorhersagefaktoren  \n",
    "3. Random Forest kann gut mit kategorialen Variablen umgehen\n",
    "4. Der Datensatz ist gross genug für robuste Vorhersagen\n",
    "\n",
    "Verbesserungspotenzial:\n",
    "1. Integration von Wetterinformationen\n",
    "2. Berücksichtigung von Feiertagen und Schulferien\n",
    "3. Analyse von Wochentag-Effekten\n",
    "4. Längsschnittanalyse zur besseren Trenderfassung\n",
    "\"\"\"\n",
    "print(summary)\n",
    "\n",
    "# Tatsächlich vs. Vorhergesagt Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Tatsächliche Zugzahlen')\n",
    "plt.ylabel('Vorhergesagte Zugzahlen')\n",
    "plt.title('Tatsächlich vs. Vorhergesagt - Zugzahlen')\n",
    "plt.tight_layout()\n",
    "plt.savefig('actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalyse abgeschlossen!\")\n",
    "print(\"\\nErstellt wurden folgende Dateien:\")\n",
    "print(\"- feature_importance.png\")\n",
    "print(\"- confusion_matrix.png\")\n",
    "print(\"- actual_vs_predicted.png\")\n",
    "print(\"\\nBereit für Teil 4 der Leistungsbeurteilung!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48406404-727d-47db-8dcc-da55eb769f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
